# performance optimizations
spark.serializer                org.apache.spark.serializer.KryoSerializer
spark.default.parallelism       200
spark.sql.shuffle.partitions    200

# worker node / executor set up
# expecting a worker with 12 cores and 56g of memory
spark.executor.memory           {{ .Env.SPARK_EXECUTOR_MEMORY }}
spark.executor.cores            {{ .Env.SPARK_WORKER_CORES }}
spark.executor.extraJavaOptions -XX:+UseG1GC

# driver configurations
spark.driver.memory             {{ .Env.SPARK_DRIVER_MEMORY }}
spark.driver.memoryOverhead	3g
spark.driver.cores              {{ .Env.SPARK_DRIVER_CORES }}
spark.driver.extraJavaOptions -XX:+UseG1GC


# operational configurations
spark.logConf                   true
spark.worker.cleanup.enabled    true

# This setting is to tell the class loaders in Spark that they
# only need to load the QFS access libraries once
spark.sql.hive.metastore.sharedPrefixes         com.quantcast.qfs

# Set up retention of Spark events to enable the history server.
# The configured directory needs to be created prior to launching
# Spark master.
spark.eventLog.enabled              true
spark.eventLog.dir                  qfs:///history/spark-event/
spark.history.fs.logDirectory       qfs:///history/spark-event/
spark.history.fs.cleaner.maxAge     30d

# Configure QFS here rather than in core-site.xml
spark.hadoop.fs.qfs.impl            com.quantcast.qfs.hadoop.QuantcastFileSystem2
spark.hadoop.fs.defaultFS           qfs://{{ .Env.QFS_METASERVER_HOSTNAME }}:{{ .Env.QFS_METASERVER_PORT }}
spark.hadoop.fs.qfs.metaServerHost  {{ .Env.QFS_METASERVER_HOSTNAME }}
spark.hadoop.fs.qfs.metaServerPort  {{ .Env.QFS_METASERVER_PORT }}

# this spark.hadoop.fs.qfs.createParams	configure causes files written by Spark to
# QFS to be 2x replicated  rather than using Reed-Solomon encoding. If you have at
# least 9 chunkservers, remove this configuration to instead use Reed-Solomon encoding.
spark.hadoop.fs.qfs.createParams    {{ .Env.QFS_REPLICATION_FACTOR }}
